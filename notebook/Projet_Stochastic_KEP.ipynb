{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5MA Sujet de projet\n",
    "\n",
    "# Transfert d'organe sous incertitude sur la compatibilité"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Malgré l'augmentation croissante du nombre de transplantations d'organes effectuées chaque année (environ 6000 en 2017 dont 3782 transplantations de reins), la demande reste en perpétuelle augmentation. Ainsi 6000 organes, dont 3782 reins, ont été transplantés en 2017, mais il y avait encore 24000 personnes en attente d'un organe la même année. Les organes transplantés peuvent provenir d'un donneur décédé ou, dans le cas des reins et du foie, d'un donneur vivant consentant, le plus souvent membre de la famille du patient. Hélas, même si un proche accepte de prendre ce risque pour sa santé, il ne sera pas forcément compatible avec le patient. Pour cette raison, les pratiques médicales les législations évoluent dans de nombreux pays afin de permettre la mise en place d'un programme d'échange de dons d'organes.\n",
    "\n",
    "L'exemple le plus simple d'échange de don d'organes est celui où deux patients $P_1$ et $P_2$ sont accompagnés de donneurs $D_1$ et $D_2$. Les patients sont supposés incompatibles avec les donneurs qui les accompagnent, mais on suppose que $D_1$ est compatible avec $P_2$ et $D_2$ avec $P_1$. Il est alors possible de transplanter un organe de $D_1$ vers $P_2$ et de $D_2$ vers $P_1$ avec le consentement de tous et en suivant la procédure légale.\n",
    "\n",
    "Plus généralement, un cycle d'échange d'organes associe $k$ paires de patient-donneur $(P_{i_1},D_{i_1}), \\dots, P_{i_k},D_{i_k})$ de sorte que $D_{i_l}$ donne à $P_{i_{l+1}}$ pour $l=1,\\dots,k-1$ et $D_{i_k}$ donne à $P_{i_1}$.\n",
    "Par ailleurs, le point essentiel est que les transferts soient tous réalisés en même temps et dans le même hôpital pour éviter qu'une rétractation de dernière minute ne lèse un patient et son donneur, et que les patients et donneurs venus ensemble et leur famille puissent se soutenir émotionnellement durant l'hospitalisation. \n",
    "Pour cette raison, le nombre d'échanges prenant place au sein d'un même cycle est nécessairement limité. En pratique, l'organisation d'un cycle de trois paires est déjà une épreuve pour le personnel d'un hôpital, et le plus grand cycle ayant jamais eu lieu a a impliqué six patients et donneurs.\n",
    "\n",
    "Dans ce projet, nous prendrons le point de vue de l'organisme national responsable de la gestion du programme d'échange d'organes. \n",
    "À chaque phase d'échange, l'objectif de cet organisme est de choisir un ensemble de cycles d'échanges entre paires compatibles afin de maximiser le nombre de patients recevant un organe. Dans certains cas, on peut aussi donner une priorité à certains patients en fonction de la gravité de leur état ou de la durée de leur attente. \n",
    "Pour cela, on pourra attribuer des poids différents à chaque patient et maximiser la somme des poids des patients recevant un organe. \n",
    "\n",
    "Lors d'une première phase de planification, l'organisme ne dispose que de données individuelles sur chaque donneur et chaque receveur pour déduire la compatibilité entre donneurs et patients. \n",
    "Ces données sont principalement le groupe sanguin et le complexe majeur d’histocompatibilité, aussi appelé système HLA. \n",
    "Ils en tirent un premier graphe de compatibilité orienté, $G=(V,A)$, où chaque sommet de $V$ représente une paire donneur-patient et où un arc entre deux paires $(P_k,D_k)$ et $(P_l,D_l)$ signifie que $D_k$ est __a priori__ compatible avec $P_l$.\n",
    "Cependant, la compatibilité effective entre deux personnes ne peut être assurée qu'en mettant en présence des tissus des deux personnes dans ce que l'on appelle un _test croisé_. \n",
    "En général, on peut supposer que les données individuelles permettent de déterminer une probabilité de réussite du test croisé.\n",
    "Mais, dans tous les cas, ces tests peuvent être lourds à réaliser pour les patients et demander des ressources importantes aupèrs des services hospitaliers, donc leur nombre sera toujours limité. \n",
    "On pourra pour cela considérer une limite fixe, une limite dépendant du nombre de paires patient-donneur ou bien supposer que les tests ne servent qu'à confirmer la compatibilité après avoir décidé les cycles d'échange entre patients a priori compatibles. \n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "Ici on distingue bien un problème de type optimisation sous incertitude. On une décision à priori qui est les cycles que nous choisissons et ensuite nous réalisons des tests. Ces différents tests nous permettront de nous assurer à postériori des différentes compatibilités réelles.\n",
    "\n",
    "TODO : définir les variables à priori et les variables de recours $x$ seront les variables à priori et $y$ seront les variables de recours\n",
    "\n",
    "\n",
    "- une première contrainte apparaît ici : on ne veut limiter la longueure des cycles. Si on considère des cycles qui sont trop longs on va avoir des problèmes dans notre mise en place à l'hopital.\n",
    "\n",
    "- il y aura ensuite tout un ensemble de contraintes qui nous permettront de définir ce que l'on appel des cycles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description des données\n",
    "\n",
    "Des jeux de données correspondant à des ensembles de paires patient-donneur ont été partagés dans la PrefLib (https://www.preflib.org/data/MD). Le sous-ensemble d'instances auxquels vous pourrez vous intéresser dans un premier temps accompagne ce sujet sur Moodle. Les dix premières instances (numérotées de 1 à 10) contiennent 10 paires patient-donneur, les 10 suivantes (numérotées de 31 à 40) en contiennent 32 et les 10 dernières (numérotées de 71 à 80) en contiennent 64. Chaque jeu de données est décrit par deux fichiers, l'un énumérant les données relatives à chaque paire et portant l'extension .dat, et l'autre énumérant les données relatives aux arcs et portant l'extension .wmd.\n",
    "Nous vous fournissons une fonction permettant de lire les fichiers relatifs à un jeu de donnéees. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois le graphe de compatibilité donné, une instance est entièrement décrite par la connaissance de la distribution des incertitudes dans une approche par optimisation stochastique. Dans une approche par optimisation robuste, le pire cas est déjà connu pour chaque arête, il s'agit d'un échec de la transplantation. Plusieurs modèles d'incertitudes sont classiquement regardés dans la littérature, mais tous considèrent que la réussite du test croisé réalisé sur un arc $a$ suit une loi de Bernouilli de probabilité $1-f_a$ où $f_a$ est une probabilité d'échec donnée. Nous donnons ci-dessous la fonction permettant de calculer des probabilités d'échec pour tous les arcs en fonction d'un paramètre à choisir dans le tableau DISTRIBUTIONS.\n",
    "\n",
    "---\n",
    "\n",
    "Sur chaque arrète on va avoir la probabilité que le transplantation soit réussit ou pas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Travail à réaliser\n",
    "\n",
    "Nous vous donnons une grande liberté sur la façon de traiter le sujet. En fonction de décisions que vous justifierez, vous pourrez traiter le problème par une approche d'optimisation stochastique, d'optimisation robuste ou de toute autre approche averse aux risques. Le travail commencera par décrire l'approche suivie puis le modèle en découlant. Un code Julia permettra ensuite d'implémenter une ou plusieurs méthodes de résolution pour le modèle. Vous pourrez tester la ou les méthodes sur des instances de la PrefLib. Vos interprétations devront rendre compte des enjeux pratiques et des enjeux algorithmiques (optimalité, temps de calcul, passage à l'échelle, etc.) de votre travail.\n",
    "Le résultat de votre travail sera à rendre dans ce notebook avant le 14 janvier 2022. Chaque cellule du notebook aura préalablement été exécutée (sans erreur, évidemment), et il importera que les affichages utilisés dans vos interprétations y apparaissent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baptc\\Documents\\GM\\INSA\\3A\\S9\\Optimisation sous incertitudes\\KidneyExchangeProgram\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "check that here the path ends with `KidneyExchangeProgram`, the git name\n",
    "\"\"\"\n",
    "\n",
    "while(last(split(pwd(), Base.Filesystem.path_separator)) != \"KidneyExchangeProgram\")\n",
    "    cd(\"..\")\n",
    "end\n",
    "println(pwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "getClusterUsefull"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Random, MetaGraphs, SimpleWeightedGraphs, Graphs, JuMP, DelimitedFiles, Distributions, Plots, GraphPlot\n",
    "\n",
    "# include files for the data reading and data extraction\n",
    "include(join([\"utils\", \"graph_extraction.jl\"], Base.Filesystem.path_separator))\n",
    "include(join([\"utils\", \"data_reading.jl\"], Base.Filesystem.path_separator))\n",
    "\n",
    "# include files for the modeling and solving part\n",
    "## stochastic optimization\n",
    "include(join([\"src\", \"stochastic_framework\", \"master_problem.jl\"], Base.Filesystem.path_separator))\n",
    "include(join([\"src\", \"stochastic_framework\", \"recourse_problem.jl\"], Base.Filesystem.path_separator))\n",
    "\n",
    "\n",
    "# for the random simulations\n",
    "include(join([\"utils\", \"monte_carlo.jl\"], Base.Filesystem.path_separator))\n",
    "\n",
    "# for displaying the solution\n",
    "include(join([\"utils\", \"visualization.jl\"], Base.Filesystem.path_separator))\n",
    "    \n",
    "# for solution extraction\n",
    "include(join([\"utils\", \"solution_extraction.jl\"], Base.Filesystem.path_separator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(join([\"src\", \"dtm_framework\", \"complete_recourse.jl\"], Base.Filesystem.path_separator))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Les données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons travailler ici avec des données sous forme de graphes. Les fonctions `read_kep_file` et `get_failure_rates` du fichier `.\\utils\\data_reading.jl` nous permettent de lire les fichier de données correspondant au problème de construire le graphe correspondant et ensuite de venir calculer les probabilités d'échec (du test croisé) de chaque arc. Voici un exemple d'utilisation des deux premières fonctions :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kep_graph = read_kep_file(\"./_cache/data/MD-00001-00000080.wmd\",\"./_cache/data/MD-00001-00000080.dat\");\n",
    "failure_rates = get_failure_rates(kep_graph, \"Constant\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction `extractCycleInformation` du fichier `.\\utils\\graph_extraction.jl`, nous permettra de venir extraire des données du graph crée. Cette fonction est orienté sur les cycles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(@doc(extractCycleInformation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_data = extractCycleInformation(kep_graph, 3, \"sum\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Un problème (presque) à recourt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notre première vision de ce problème était de réfléchir uniquement sur les cycles. Nous adoptons la philosophie qui consiste à dire que on sélectionne des cycles et nous ne réalisons les tests croisés que parmis les cycles que nous avons sélectionnés\n",
    "\n",
    "On définit ainsi les données suivantes :\n",
    "\n",
    "- $C$ : l'ensemble des cycles de longueurs au plus $K$\n",
    "- $\\forall c \\in C \\quad w_c$ : désignera l'utilité du cycle $c$\n",
    "- $\\forall ~c~\\in C\\quad \\xi_c(\\omega) \\in \\{0, 1\\} = 1$ : si et seulement si on ne peut pas sélectionner le cycle $c$ (les tests sont mauvais) pour la réalisation $\\omega$\n",
    "\n",
    "On définit les variables suivantes\n",
    "\n",
    "- $1^{er}$ niveau : $\\forall c \\in C\\quad x_c \\in \\{0, 1\\} = 1$ si et seulement si, on décide de sélectionner le cycle $c$.\n",
    "- recours : $\\forall c \\in C\\quad y_c \\in \\{0, 1\\} = 1$ on ne peut pas sélectionner le cycle $c$ suite à la réalisation des tests.\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\t(\\mathbb{CRP}) := \\left\\{\\begin{aligned}\n",
    "        \\underset{x}{\\min} \\quad & - \\sum_{c \\in C} x_cw_c +\\mathbb{E}\\left(\\underset{y}{\\min} \\left[\\sum_{c \\in C} y_cw_c\\right]\\right)\\\\\n",
    "         s.c \\quad &\\sum_{c\\in C_i}x_c\\leq 1~\\forall i \\in V\\\\ % contrainte déterministe\n",
    "         % les contraintes stochastiques\n",
    "         & y_c = \\xi_c(\\omega)~x_c\\quad \\forall c \\in C \\quad \\forall \\omega \\in \\Omega\\\\ \n",
    "         & x_c \\in \\{0,1\\} \\quad \\forall c \\in C\\\\\n",
    "         & y_c \\in \\{0,1\\} \\quad \\forall c \\in C\n",
    "\t\\end{aligned}\\right.\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "Nous pouvons ainsi reformuler ce problème de la façon suivante :\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\t(\\mathbb{CRP}) := \\left\\{\\begin{aligned}\n",
    "        \\underset{x}{\\min} \\quad & - \\sum_{c \\in C} x_cw_c +\\mathbb{E}\\left( \\left[\\sum_{c \\in C} \\xi_cx_cw_c\\right]\\right)\\\\\n",
    "         s.c \\quad &\\sum_{c\\in C_i}x_c\\leq 1~\\forall i \\in V\\\\ % contrainte déterministe\n",
    "         & x_c \\in \\{0,1\\} \\quad \\forall c \\in C\\\\\n",
    "\t\\end{aligned}\\right.\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "Nous obtenons finalement :\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\t(\\mathbb{CRP}) := \\left\\{\\begin{aligned}\n",
    "        \\underset{x}{\\min} \\quad & \\sum_{c \\in C} x_cw_c(\\mathbb{E} \\left[ \\xi_c\\right] - 1)\\\\\n",
    "         s.c \\quad &\\sum_{c\\in C_i}x_c\\leq 1~\\forall i \\in V\\\\ % contrainte déterministe\n",
    "         & x_c \\in \\{0,1\\} \\quad \\forall c \\in C\\\\\n",
    "\t\\end{aligned}\\right.\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "Avec $\\mathbb{E}[\\xi_c] = \\mathbb{P}\\{\\xi_c = 1\\}$ d'où $\\mathbb{E}[\\xi_c] - 1 = -\\mathbb{P}\\{\\xi_c = 0\\}$\n",
    "\n",
    "\n",
    "Ainsi nous avons :\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\t(\\mathbb{CRP}) := \\left\\{\\begin{aligned}\n",
    "        \\underset{x}{\\max} \\quad & \\sum_{c \\in C} x_cw_c(\\mathbb{P}\\{\\xi_c = 0\\})\\\\\n",
    "         s.c \\quad &\\sum_{c\\in C_i}x_c\\leq 1~\\forall i \\in V\\\\ % contrainte déterministe\n",
    "         & x_c \\in \\{0,1\\} \\quad \\forall c \\in C\\\\\n",
    "\t\\end{aligned}\\right.\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "\n",
    "Ainsi nous pourrons note $\\tilde{w}_c = w_c \\times \\mathbb{P}\\{\\xi_c = 0\\}$, la nouvelle utilité d'un cycle qui sera en faite une combinaison entre l'utilité réelle du cyle $w_c$ et la probabilité que ce dernier se réalise. Nous pouvons ici que un cycle avec $w_c$ grand mais une probabilité de succés très faible aura peu de chance d'être choisi. En effet pourquoi choisir ce cycle si on sait qu'il n'a aucune chance (ou presque) de se réaliser.\n",
    "\n",
    "Nous avons finalement le problème suivante :\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\t(\\mathbb{CRP}) := \\left\\{\\begin{aligned}\n",
    "        \\underset{x}{\\max} \\quad & \\sum_{c \\in C} x_c\\hat{w}_c\\\\\n",
    "         s.c \\quad &\\sum_{c\\in C_i}x_c\\leq 1~\\forall i \\in V\\\\ % contrainte déterministe\n",
    "         & x_c \\in \\{0,1\\} \\quad \\forall c \\in C\\\\\n",
    "\t\\end{aligned}\\right.\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "Nous pouvons voir ainsi que ce problème $\\mathbb{CRP}$ est donc un problème totalement déterministe. Nous proposons la méthode `completRecourseProblem` dans le fichier `dtm_framework/complete_recourse.jl`. Pour résoudre ce dernier. Cette dernière fonction possède la signature suivante :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(@doc(completRecourseProblem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data\n",
    "kep_graph = read_kep_file(\"./_cache/data/MD-00001-00000080.wmd\",\"./_cache/data/MD-00001-00000080.dat\");\n",
    "failure_rates = get_failure_rates(kep_graph, \"Constant\");\n",
    "data = extractCycleInformation(kep_graph, 3, \"sum\");\n",
    "\n",
    "# the model\n",
    "res = completRecourseProblem(data[\"Cycles_index\"], data[\"vertic_cycles\"], data[\"U\"], 1 .-data[\"P\"]);\n",
    "model = res[\"model\"]\n",
    "\n",
    "optimize!(model)\n",
    "\n",
    "solution = value.(model[:x])\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## La méthode des clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les différents hopitaux nous ont contactés et nous ont expliqués que ce n'était pas à nous de dicter les tests à faire entre les différents patients. Ceci relève du domaine médicale et des infrastructure présentes dans chaque hopitaux. Il est attendu de nous de regrouper les pairs donneur receveur sous la forme de groupes pertinents. Les groupes formés alors seront pris en charge par un hôpital et au sein d'un groupe de personne toutes les différentes batteries de tests vont avoir lieu et permettront de déterminer les échanges à réaliser. Pour des raisons logistiques les hopitaux souhaitent aussi ne prendre en charge que des groupes de tailles raisonables. On notera dans la suite par la constante, $U$ la taille maximale des groupes autorisés. En effet sans une telle contrainte, nous pourrions mettre tous les patients dans le même groupe, réaliser tous les tests possibles et ensuite réaliser les échanges (Impossible !).\n",
    "\n",
    "Notre objectif est alors le suivant, former des groupes (*cluster*) de personnes qui seront ensuites pris en charges par les hopitaux. Les clusters formés comme indiqués doivent être pertinents. Ils doivent permettre en moyenne de maximiser l'utilité des échanges que l'on génère.\n",
    "\n",
    "Nous pouvons modéliser tout ceci de manière plus formelle sous la forme d'un problème d'optimisation stochastique avec recours. Nous noterons tout d'abord $C_K$ l'ensemble des cycles, du graph d'échange, de longueure $K$ ou moins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data\n",
    "kep_graph = read_kep_file(\"./_cache/data/MD-00001-00000001.wmd\",\"./_cache/data/MD-00001-00000001.dat\");\n",
    "failure_rates = get_failure_rates(kep_graph, \"Constant\");\n",
    "data = extractCycleInformation(kep_graph, 3, \"sum\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = masterClusterProblem(kep_graph, 4, data[\"Cycles_index\"], data[\"Cycles\"], data[\"U\"], data[\"vertic_cycles\"])\n",
    "\n",
    "optimize!(res[\"model\"])\n",
    "# gr()\n",
    "# heatmap(1:size(sol, 1), 1:size(sol, 2), sol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotSolutionCluster(kep_graph, getClusterUsefull(getCluster(kep_graph, sol)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Méthode en L : Coupes de Benders\n",
    "Dans le problème présentée précédemment nous avons finalement le problème de recours $v_k(x)$ qui peut se présenter sous la forme suivante :\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\tv_k(x):= \\left\\{\\begin{aligned}\n",
    "        \\underset{y}{\\max} \\quad & \\sum_{c \\in C_{K}}y_c w_c\\\\\n",
    "         s.c & \\quad y_c \\leq x_{i,j} \\xi_{i,j}^k \\quad \\forall (i,j) \\in c ~,~\\forall c \\in C_K \\\\\n",
    "         & \\sum_{c \\in C_i} y_c \\leq 1 \\quad \\forall i \\in V \\\\\n",
    "         & y_c \\leq 1 \\quad \\forall c \\in C_K\n",
    "\t\\end{aligned}\\right.\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "Nous pouvons proposer un dual pour ce problème :\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\td_k(x):= \\left\\{\\begin{aligned}\n",
    "        \\underset{y}{\\min} \\quad & \\sum_{c \\in C_{K}}\\sum_{(i,j) \\in c} \\lambda_{(i,j)}^c x_{i,j}\\xi_{i,j}^k + \\sum_{i \\in V}\\mu_i + \\sum_{c \\in C_K} \\Delta_c\\\\\n",
    "         s.c & \\quad \\sum_{i \\in c} \\mu_i + \\Delta_c + \\sum_{(i,j) \\in c} \\lambda_{(i,j)}^c\\geq w_c \\quad \\forall c \\in C_K \\\\\n",
    "\t\\end{aligned}\\right.\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "Nous pouvons faire une remarque intéressante ici. Le polyhèdre $P$ définit par :\n",
    "\n",
    "$$\n",
    "P := \\{\\lambda, \\mu, \\Delta \\quad |\\quad \\sum_{i \\in c} \\mu_i + \\Delta_c + \\sum_{(i,j) \\in c} \\lambda_{(i,j)}^c\\geq w_c \\quad \\forall c \\in C_K\\}\n",
    "$$\n",
    "\n",
    "Ne dépend pas du scénario $k$ que l'on considère. Nous noterons, par la suite, $\\Lambda(P)$ les points extrèmes de ce polyhèdre.\n",
    "\n",
    "Par dualité forte nous avons :\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\tv_k(x):= \\left\\{\\begin{aligned}\n",
    "        \\underset{y}{\\min} \\quad & \\sum_{c \\in C_{K}}\\sum_{(i,j) \\in c} \\lambda_{(i,j)}^c x_{i,j}\\xi_{i,j}^k + \\sum_{i \\in V}\\mu_i + \\sum_{c \\in C_K} \\Delta_c\\\\\n",
    "         s.c &\\quad \\lambda, \\mu, \\Delta ~\\in~\\Lambda(P)\\\\\n",
    "\t\\end{aligned}\\right.\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "Ainsi nous avons :\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\tv_k(x):= \\left\\{\\begin{aligned}\n",
    "        \\underset{y}{\\max} \\quad & \\theta \\\\\n",
    "         s.c &\\quad \\theta \\leq \\sum_{c \\in C_{K}}\\sum_{(i,j) \\in c} \\lambda_{(i,j)}^c x_{i,j}\\xi_{i,j}^k + \\sum_{i \\in V}\\mu_i + \\sum_{c \\in C_K} \\Delta_c \\quad\\forall~\\lambda, \\mu, \\Delta ~\\in~\\Lambda(P)\\\\\n",
    "\t\\end{aligned}\\right.\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "La méthode de Benders ou méthode en L, consistera simplement à augmenter le porblème maître, en utilisant les points extrèmes du polyhèdre P.\n",
    "Générer l'ensemble des points extrèmes d'un polyhèdre requiert une complexité exponentielle. L'objectif de la méthode en L, est de ne générer que les points extrèmes qui sont intéressants pour notre problème d'optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution\n",
    "sol = value.(res[\"model\"][:x])\n",
    "\n",
    "# ksi\n",
    "ksi = getScenarioCluster(kep_graph)\n",
    "\n",
    "# C\n",
    "C = data[\"Cycles_index\"] \n",
    "\n",
    "cycles = data[\"Cycles\"]\n",
    "\n",
    "U = data[\"U\"]\n",
    "\n",
    "vertic_cycles = data[\"vertic_cycles\"];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_recourse = recourseClusterProblem(sol, ksi, C, vertic_cycles, U, cycles);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max 2 y[1] + 2 y[2]\n",
      "Subject to\n",
      " cons_delta_1 : y[1] <= 1.0\n",
      " cons_lambda_1_1_6 : y[1] <= 1.0\n",
      " cons_lambda_1_6_1 : y[1] <= 1.0\n",
      " cons_delta_2 : y[2] <= 1.0\n",
      " cons_lambda_2_3_8 : y[2] <= 1.0\n",
      " cons_lambda_2_8_3 : y[2] <= 1.0\n",
      " cons_mu_5 : 0 <= 1.0\n",
      " cons_mu_16 : 0 <= 1.0\n",
      " cons_mu_12 : 0 <= 1.0\n",
      " cons_mu_8 : y[2] <= 1.0\n",
      " cons_mu_1 : y[1] <= 1.0\n",
      " cons_mu_6 : y[1] <= 1.0\n",
      " cons_mu_11 : 0 <= 1.0\n",
      " cons_mu_9 : 0 <= 1.0\n",
      " cons_mu_14 : 0 <= 1.0\n",
      " cons_mu_3 : y[2] <= 1.0\n",
      " cons_mu_7 : 0 <= 1.0\n",
      " cons_mu_4 : 0 <= 1.0\n",
      " cons_mu_13 : 0 <= 1.0\n",
      " cons_mu_15 : 0 <= 1.0\n",
      " cons_mu_2 : 0 <= 1.0\n",
      " cons_mu_10 : 0 <= 1.0\n",
      " y[1] >= 0.0\n",
      " y[2] >= 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "println(res_recourse[\"model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0 0.0 0.0 0.0 0.0 -0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0; -0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0;;; 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0 0.0 0.0 0.0 -0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0; 0.0 0.0 -0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0]\n"
     ]
    }
   ],
   "source": [
    "println(res_recourse[\"dual\"][\"dual_lambda\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0]\n"
     ]
    }
   ],
   "source": [
    "println(res_recourse[\"dual\"][\"dual_mu\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.0, -2.0]\n"
     ]
    }
   ],
   "source": [
    "println(res_recourse[\"dual\"][\"dual_delta\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.2",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
