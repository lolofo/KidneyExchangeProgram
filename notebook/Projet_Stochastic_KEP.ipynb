{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5MA Sujet de projet\n",
    "\n",
    "# Transfert d'organe sous incertitude sur la compatibilité"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Malgré l'augmentation croissante du nombre de transplantations d'organes effectuées chaque année (environ 6000 en 2017 dont 3782 transplantations de reins), la demande reste en perpétuelle augmentation. Ainsi 6000 organes, dont 3782 reins, ont été transplantés en 2017, mais il y avait encore 24000 personnes en attente d'un organe la même année. Les organes transplantés peuvent provenir d'un donneur décédé ou, dans le cas des reins et du foie, d'un donneur vivant consentant, le plus souvent membre de la famille du patient. Hélas, même si un proche accepte de prendre ce risque pour sa santé, il ne sera pas forcément compatible avec le patient. Pour cette raison, les pratiques médicales les législations évoluent dans de nombreux pays afin de permettre la mise en place d'un programme d'échange de dons d'organes.\n",
    "\n",
    "L'exemple le plus simple d'échange de don d'organes est celui où deux patients $P_1$ et $P_2$ sont accompagnés de donneurs $D_1$ et $D_2$. Les patients sont supposés incompatibles avec les donneurs qui les accompagnent, mais on suppose que $D_1$ est compatible avec $P_2$ et $D_2$ avec $P_1$. Il est alors possible de transplanter un organe de $D_1$ vers $P_2$ et de $D_2$ vers $P_1$ avec le consentement de tous et en suivant la procédure légale.\n",
    "\n",
    "Plus généralement, un cycle d'échange d'organes associe $k$ paires de patient-donneur $(P_{i_1},D_{i_1}), \\dots, P_{i_k},D_{i_k})$ de sorte que $D_{i_l}$ donne à $P_{i_{l+1}}$ pour $l=1,\\dots,k-1$ et $D_{i_k}$ donne à $P_{i_1}$.\n",
    "Par ailleurs, le point essentiel est que les transferts soient tous réalisés en même temps et dans le même hôpital pour éviter qu'une rétractation de dernière minute ne lèse un patient et son donneur, et que les patients et donneurs venus ensemble et leur famille puissent se soutenir émotionnellement durant l'hospitalisation. \n",
    "Pour cette raison, le nombre d'échanges prenant place au sein d'un même cycle est nécessairement limité. En pratique, l'organisation d'un cycle de trois paires est déjà une épreuve pour le personnel d'un hôpital, et le plus grand cycle ayant jamais eu lieu a a impliqué six patients et donneurs.\n",
    "\n",
    "Dans ce projet, nous prendrons le point de vue de l'organisme national responsable de la gestion du programme d'échange d'organes. \n",
    "À chaque phase d'échange, l'objectif de cet organisme est de choisir un ensemble de cycles d'échanges entre paires compatibles afin de maximiser le nombre de patients recevant un organe. Dans certains cas, on peut aussi donner une priorité à certains patients en fonction de la gravité de leur état ou de la durée de leur attente. \n",
    "Pour cela, on pourra attribuer des poids différents à chaque patient et maximiser la somme des poids des patients recevant un organe. \n",
    "\n",
    "Lors d'une première phase de planification, l'organisme ne dispose que de données individuelles sur chaque donneur et chaque receveur pour déduire la compatibilité entre donneurs et patients. \n",
    "Ces données sont principalement le groupe sanguin et le complexe majeur d’histocompatibilité, aussi appelé système HLA. \n",
    "Ils en tirent un premier graphe de compatibilité orienté, $G=(V,A)$, où chaque sommet de $V$ représente une paire donneur-patient et où un arc entre deux paires $(P_k,D_k)$ et $(P_l,D_l)$ signifie que $D_k$ est __a priori__ compatible avec $P_l$.\n",
    "Cependant, la compatibilité effective entre deux personnes ne peut être assurée qu'en mettant en présence des tissus des deux personnes dans ce que l'on appelle un _test croisé_. \n",
    "En général, on peut supposer que les données individuelles permettent de déterminer une probabilité de réussite du test croisé.\n",
    "Mais, dans tous les cas, ces tests peuvent être lourds à réaliser pour les patients et demander des ressources importantes aupèrs des services hospitaliers, donc leur nombre sera toujours limité. \n",
    "On pourra pour cela considérer une limite fixe, une limite dépendant du nombre de paires patient-donneur ou bien supposer que les tests ne servent qu'à confirmer la compatibilité après avoir décidé les cycles d'échange entre patients a priori compatibles. \n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "Ici on distingue bien un problème de type optimisation sous incertitude. On une décision à priori qui est les cycles que nous choisissons et ensuite nous réalisons des tests. Ces différents tests nous permettront de nous assurer à postériori des différentes compatibilités réelles.\n",
    "\n",
    "TODO : définir les variables à priori et les variables de recours $x$ seront les variables à priori et $y$ seront les variables de recours\n",
    "\n",
    "\n",
    "- une première contrainte apparaît ici : on ne veut limiter la longueure des cycles. Si on considère des cycles qui sont trop longs on va avoir des problèmes dans notre mise en place à l'hopital.\n",
    "\n",
    "- il y aura ensuite tout un ensemble de contraintes qui nous permettront de définir ce que l'on appel des cycles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description des données\n",
    "\n",
    "Des jeux de données correspondant à des ensembles de paires patient-donneur ont été partagés dans la PrefLib (https://www.preflib.org/data/MD). Le sous-ensemble d'instances auxquels vous pourrez vous intéresser dans un premier temps accompagne ce sujet sur Moodle. Les dix premières instances (numérotées de 1 à 10) contiennent 10 paires patient-donneur, les 10 suivantes (numérotées de 31 à 40) en contiennent 32 et les 10 dernières (numérotées de 71 à 80) en contiennent 64. Chaque jeu de données est décrit par deux fichiers, l'un énumérant les données relatives à chaque paire et portant l'extension .dat, et l'autre énumérant les données relatives aux arcs et portant l'extension .wmd.\n",
    "Nous vous fournissons une fonction permettant de lire les fichiers relatifs à un jeu de donnéees. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois le graphe de compatibilité donné, une instance est entièrement décrite par la connaissance de la distribution des incertitudes dans une approche par optimisation stochastique. Dans une approche par optimisation robuste, le pire cas est déjà connu pour chaque arête, il s'agit d'un échec de la transplantation. Plusieurs modèles d'incertitudes sont classiquement regardés dans la littérature, mais tous considèrent que la réussite du test croisé réalisé sur un arc $a$ suit une loi de Bernouilli de probabilité $1-f_a$ où $f_a$ est une probabilité d'échec donnée. Nous donnons ci-dessous la fonction permettant de calculer des probabilités d'échec pour tous les arcs en fonction d'un paramètre à choisir dans le tableau DISTRIBUTIONS.\n",
    "\n",
    "---\n",
    "\n",
    "Sur chaque arrète on va avoir la probabilité que le transplantation soit réussit ou pas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Travail à réaliser\n",
    "\n",
    "Nous vous donnons une grande liberté sur la façon de traiter le sujet. En fonction de décisions que vous justifierez, vous pourrez traiter le problème par une approche d'optimisation stochastique, d'optimisation robuste ou de toute autre approche averse aux risques. Le travail commencera par décrire l'approche suivie puis le modèle en découlant. Un code Julia permettra ensuite d'implémenter une ou plusieurs méthodes de résolution pour le modèle. Vous pourrez tester la ou les méthodes sur des instances de la PrefLib. Vos interprétations devront rendre compte des enjeux pratiques et des enjeux algorithmiques (optimalité, temps de calcul, passage à l'échelle, etc.) de votre travail.\n",
    "Le résultat de votre travail sera à rendre dans ce notebook avant le 14 janvier 2022. Chaque cellule du notebook aura préalablement été exécutée (sans erreur, évidemment), et il importera que les affichages utilisés dans vos interprétations y apparaissent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\loicf\\Documents\\INSA\\GM\\5GM\\OptimIncert\\KidneyExchangeProgram\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "check that here the path ends with `KidneyExchangeProgram`, the git name\n",
    "\"\"\"\n",
    "\n",
    "while (last(split(pwd(), Base.Filesystem.path_separator)) != \"KidneyExchangeProgram\")\n",
    "    cd(\"..\")\n",
    "end\n",
    "println(pwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "getClusterUsefull"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Random, MetaGraphs, SimpleWeightedGraphs, Graphs, JuMP, DelimitedFiles, Distributions, Plots, GraphPlot, HiGHS, DataFrames\n",
    "# JLD\n",
    "\n",
    "# include files for the data reading and data extraction\n",
    "include(join([\"utils\", \"graph_extraction.jl\"], Base.Filesystem.path_separator))\n",
    "include(join([\"utils\", \"data_reading.jl\"], Base.Filesystem.path_separator))\n",
    "\n",
    "# include files for the modeling and solving part\n",
    "\n",
    "## stochastic optimization\n",
    "include(join([\"src\", \"stochastic_framework\", \"master_problem.jl\"], Base.Filesystem.path_separator))\n",
    "include(join([\"src\", \"stochastic_framework\", \"recourse_problem.jl\"], Base.Filesystem.path_separator))\n",
    "include(join([\"src\", \"stochastic_framework\", \"unroll_problem.jl\"], Base.Filesystem.path_separator))\n",
    "include(join([\"src\", \"stochastic_framework\", \"solver.jl\"], Base.Filesystem.path_separator))\n",
    "include(join([\"src\", \"stochastic_framework\", \"solution_evaluation.jl\"], Base.Filesystem.path_separator))\n",
    "\n",
    "## deterministic optimization\n",
    "include(join([\"src\", \"dtm_framework\", \"complete_recourse.jl\"], Base.Filesystem.path_separator))\n",
    "\n",
    "# for the random simulations\n",
    "include(join([\"utils\", \"monte_carlo.jl\"], Base.Filesystem.path_separator))\n",
    "\n",
    "# for displaying the solution\n",
    "include(join([\"utils\", \"visualization.jl\"], Base.Filesystem.path_separator))\n",
    "include(join([\"utils\", \"sum_up.jl\"], Base.Filesystem.path_separator))\n",
    "    \n",
    "# for solution extraction\n",
    "include(join([\"utils\", \"solution_extraction.jl\"], Base.Filesystem.path_separator))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Les données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons travailler ici avec des données sous forme de graphes. Les fonctions `read_kep_file` et `get_failure_rates` du fichier `.\\utils\\data_reading.jl` nous permettent de lire les fichier de données correspondant au problème de construire le graphe correspondant et ensuite de venir calculer les probabilités d'échec (du test croisé) de chaque arc. Voici un exemple d'utilisation des deux premières fonctions :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "kep_graph = read_kep_file(\"./_cache/data/MD-00001-00000080.wmd\",\"./_cache/data/MD-00001-00000080.dat\");\n",
    "failure_rates = get_failure_rates(kep_graph, \"Constant\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction `extractCycleInformation` du fichier `.\\utils\\graph_extraction.jl`, nous permettra de venir extraire des données du graph crée. Cette fonction est orienté sur les cycles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```\n",
      "extractCycleInformation\n",
      "```\n",
      "\n",
      "This function allow us to extract the relevant information from the kep*graph. The relevant information here concern the cycle formulation of the kep*graph.\n",
      "\n",
      "# Parameters\n",
      "\n",
      "  * `g` : the kep_graph\n",
      "  * `K` (int): the length of the Cycles\n",
      "  * `mode`: the method to use to compute the calculus of the utilities\n",
      "\n",
      "# Return\n",
      "\n",
      "This function returns a Julia dictionnary with the following keys :\n",
      "\n",
      "  * `Cycles_index` : a list of integer each element of the list corresponds to the index of a cycle\n",
      "  * `vertic_cycles` : a dictionnary with vertices as keys and a list of cycles which involve the key as value\n",
      "  * `Cycles` : the exhaustive enumeration of the cycles\n",
      "  * `P` : for each cycle, the probability of failure. To get the success do 1 - ...\n",
      "  * `U` : the utility of each cycle\n"
     ]
    }
   ],
   "source": [
    "print(@doc(extractCycleInformation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_data = extractCycleInformation(kep_graph, 3, \"sum\");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Un problème (presque) à recours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notre première vision de ce problème était de réfléchir uniquement sur les cycles. Nous adoptons la philosophie qui consiste à dire que on sélectionne des cycles et nous ne réalisons les tests croisés que parmis les cycles que nous avons sélectionnés\n",
    "\n",
    "On définit ainsi les données suivantes :\n",
    "\n",
    "- $C$ : l'ensemble des cycles de longueurs au plus $K$\n",
    "- $\\forall c \\in C \\quad w_c$ : désignera l'utilité du cycle $c$\n",
    "- $\\forall ~c~\\in C\\quad \\xi_c(\\omega) \\in \\{0, 1\\} = 1$ : si et seulement si on ne peut pas sélectionner le cycle $c$ (les tests sont mauvais) pour la réalisation $\\omega$\n",
    "\n",
    "On définit les variables suivantes\n",
    "\n",
    "- $1^{er}$ niveau : $\\forall c \\in C\\quad x_c \\in \\{0, 1\\} = 1$ si et seulement si, on décide de sélectionner le cycle $c$.\n",
    "- recours : $\\forall c \\in C\\quad y_c \\in \\{0, 1\\} = 1$ on ne peut pas sélectionner le cycle $c$ suite à la réalisation des tests.\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\t(\\mathbb{CRP}) := \\left\\{\\begin{aligned}\n",
    "        \\underset{x}{\\min} \\quad & - \\sum_{c \\in C} x_cw_c +\\mathbb{E}\\left(\\underset{y}{\\min} \\left[\\sum_{c \\in C} y_cw_c\\right]\\right)\\\\\n",
    "         s.c \\quad &\\sum_{c\\in C_i}x_c\\leq 1~\\forall i \\in V\\\\ % contrainte déterministe\n",
    "         % les contraintes stochastiques\n",
    "         & y_c = \\xi_c(\\omega)~x_c\\quad \\forall c \\in C \\quad \\forall \\omega \\in \\Omega\\\\ \n",
    "         & x_c \\in \\{0,1\\} \\quad \\forall c \\in C\\\\\n",
    "         & y_c \\in \\{0,1\\} \\quad \\forall c \\in C\n",
    "\t\\end{aligned}\\right.\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "Nous pouvons ainsi reformuler ce problème de la façon suivante :\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\t(\\mathbb{CRP}) := \\left\\{\\begin{aligned}\n",
    "        \\underset{x}{\\min} \\quad & - \\sum_{c \\in C} x_cw_c +\\mathbb{E}\\left( \\left[\\sum_{c \\in C} \\xi_cx_cw_c\\right]\\right)\\\\\n",
    "         s.c \\quad &\\sum_{c\\in C_i}x_c\\leq 1~\\forall i \\in V\\\\ % contrainte déterministe\n",
    "         & x_c \\in \\{0,1\\} \\quad \\forall c \\in C\\\\\n",
    "\t\\end{aligned}\\right.\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "Nous obtenons finalement :\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\t(\\mathbb{CRP}) := \\left\\{\\begin{aligned}\n",
    "        \\underset{x}{\\min} \\quad & \\sum_{c \\in C} x_cw_c(\\mathbb{E} \\left[ \\xi_c\\right] - 1)\\\\\n",
    "         s.c \\quad &\\sum_{c\\in C_i}x_c\\leq 1~\\forall i \\in V\\\\ % contrainte déterministe\n",
    "         & x_c \\in \\{0,1\\} \\quad \\forall c \\in C\\\\\n",
    "\t\\end{aligned}\\right.\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "Avec $\\mathbb{E}[\\xi_c] = \\mathbb{P}\\{\\xi_c = 1\\}$ d'où $\\mathbb{E}[\\xi_c] - 1 = -\\mathbb{P}\\{\\xi_c = 0\\}$\n",
    "\n",
    "\n",
    "Ainsi nous avons :\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\t(\\mathbb{CRP}) := \\left\\{\\begin{aligned}\n",
    "        \\underset{x}{\\max} \\quad & \\sum_{c \\in C} x_cw_c(\\mathbb{P}\\{\\xi_c = 0\\})\\\\\n",
    "         s.c \\quad &\\sum_{c\\in C_i}x_c\\leq 1~\\forall i \\in V\\\\ % contrainte déterministe\n",
    "         & x_c \\in \\{0,1\\} \\quad \\forall c \\in C\\\\\n",
    "\t\\end{aligned}\\right.\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "\n",
    "Ainsi nous pourrons note $\\tilde{w}_c = w_c \\times \\mathbb{P}\\{\\xi_c = 0\\}$, la nouvelle utilité d'un cycle qui sera en faite une combinaison entre l'utilité réelle du cyle $w_c$ et la probabilité que ce dernier se réalise. Nous pouvons ici que un cycle avec $w_c$ grand mais une probabilité de succés très faible aura peu de chance d'être choisi. En effet pourquoi choisir ce cycle si on sait qu'il n'a aucune chance (ou presque) de se réaliser.\n",
    "\n",
    "Nous avons finalement le problème suivante :\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\t(\\mathbb{CRP}) := \\left\\{\\begin{aligned}\n",
    "        \\underset{x}{\\max} \\quad & \\sum_{c \\in C} x_c\\hat{w}_c\\\\\n",
    "         s.c \\quad &\\sum_{c\\in C_i}x_c\\leq 1~\\forall i \\in V\\\\ % contrainte déterministe\n",
    "         & x_c \\in \\{0,1\\} \\quad \\forall c \\in C\\\\\n",
    "\t\\end{aligned}\\right.\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "Nous pouvons voir ainsi que ce problème $\\mathbb{CRP}$ est donc un problème totalement déterministe. Nous proposons la méthode `completRecourseProblem` dans le fichier `dtm_framework/complete_recourse.jl`. Pour résoudre ce dernier. Cette dernière fonction possède la signature suivante :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```\n",
      "completRecourseProblem\n",
      "```\n",
      "\n",
      "This is the deterministic version of the problem with the complete recourse.\n",
      "\n",
      "# Parameters\n",
      "\n",
      "  * `C` : index of the cycles\n",
      "  * `vertic_cycles` : a dictionnary, at the key i of this list, give the a list of the index of the cycles which involve the node i\n",
      "  * `U` : the utilities of each cycle in the graph.\n",
      "  * `S_P` : probability of sucess of each cycle\n"
     ]
    }
   ],
   "source": [
    "print(@doc(completRecourseProblem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data\n",
    "kep_graph = read_kep_file(\"./_cache/data/MD-00001-00000080.wmd\",\"./_cache/data/MD-00001-00000080.dat\");\n",
    "failure_rates = get_failure_rates(kep_graph, \"Constant\");\n",
    "data = extractCycleInformation(kep_graph, 3, \"sum\");\n",
    "\n",
    "# the model\n",
    "res = completRecourseProblem(data[\"Cycles_index\"], data[\"vertic_cycles\"], data[\"U\"], 1 .-data[\"P\"]);\n",
    "model = res[\"model\"]\n",
    "\n",
    "optimize!(model)\n",
    "\n",
    "solution = value.(model[:x])\n",
    ";"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## La méthode des *clusters*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les différents hopitaux nous ont contactés et nous ont expliqués que ce n'était pas à nous de dicter les tests à faire entre les différents patients. Ceci relève du domaine médicale et des infrastructure présentes dans chaque hopitaux. Il est attendu de nous de regrouper les pairs donneur receveur sous la forme de groupes pertinents. Les groupes formés alors seront pris en charge par un hôpital et au sein d'un groupe de personne toutes les différentes batteries de tests vont avoir lieu et permettront de déterminer les échanges à réaliser. Pour des raisons logistiques les hopitaux souhaitent aussi ne prendre en charge que des groupes de tailles raisonables. On notera dans la suite par la constante, $U$ la taille maximale des groupes autorisés. En effet sans une telle contrainte, nous pourrions mettre tous les patients dans le même groupe, réaliser tous les tests possibles et ensuite réaliser les échanges (Impossible !).\n",
    "\n",
    "Notre objectif est alors le suivant, former des groupes (*cluster*) de personnes qui seront ensuites pris en charges par les hopitaux. Les clusters formés comme indiqués doivent être pertinents. Ils doivent permettre en moyenne de maximiser l'utilité des échanges que l'on génère.\n",
    "\n",
    "Nous pouvons modéliser tout ceci de manière plus formelle sous la forme d'un problème d'optimisation stochastique avec recours. Nous noterons tout d'abord $C_K$ l'ensemble des cycles, du graph d'échange, de longueure $K$ ou moins. L'ensemble des scénarios possibles pour les différents tests croisés sera noté $\\Omega$ et on notera $\\omega$ une réalisation de l'ensemble des tests croisés. A noter que un scénario $\\omega$ ne correpond pas à la réalisation de un test croisé, mais bien de l'ensemble des tests croisés dans le graphe d'échange.\n",
    "\n",
    "Nous considérerons les variables :\n",
    "\n",
    "- 1er niveau : $\\forall (i,j) \\in V\\times V\\quad x_{i,j} \\in \\{0,1\\} = 1$ ssi $i$ et $j$ sont dans le même groupe.\n",
    "- recours : $\\forall c \\in C_K \\quad y_c(\\omega) \\in \\{0,1\\}=1$ ssi on décide de choisir le cycle $c$ pour réaliser les échanges dans le scénario $\\omega$.\n",
    "\n",
    "Nous définission le *cluster problem* de la manière suivante :\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\t\\mathbb{CP}:= \\left\\{\\begin{aligned}\n",
    "        \\underset{y}{\\max} &\\quad \\mathbb{E}_{\\omega}\\left[y_c(\\omega) w_c\\right]\\\\\n",
    "         s.c &\\quad x_{i,j} = x_{j,i}\\quad \\forall (i,j) \\in V\\times V\\\\\n",
    "         &\\quad x_{i,j} + x_{j,k} -1 \\leq x_{i,k} \\quad \\forall (i,j,k) \\in V\\times V\\times V\\\\\n",
    "         &\\quad \\sum_{j \\in V} x_{i,j} \\leq U \\quad \\forall i \\in V \\\\\n",
    "         &\\quad y_c(\\omega) \\leq x_{i,j}\\xi_{i,j}(\\omega) \\quad \\forall c \\in C_k, ~\\forall (i,j) \\in c,~ \\forall \\omega \\in \\Omega \\\\\n",
    "         &\\quad \\sum_{c \\in C_K(i)} y_c(\\omega) \\leq 1 \\quad \\forall i \\in V,\\quad\\forall \\omega \\in \\Omega\\\\\n",
    "\t\\end{aligned}\\right.\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "Nous pouvons faire plusieurs remarques sur ce problème :\n",
    "\n",
    "- Tout d'abord, nous pouvons voir que la variable de premier recours nous donne certes la formation des clusters, mais la variables de recours correspond pour chaque scénario $\\omega$ à la variable de décision du problème déterministe vu dans les sections précédentes.\n",
    "\n",
    "- Ce problème est un problème qui est à recours relatif complet. En effet nous pouvons voir que peut importe la valeur de $x$ que l'on prend nous pourrons choisir une valeur de $y$ pour chaque scénério qui sera réalisable. Pour vérifier ceci il suffit de se placer au pire cas qui est lorsque $x$ vaut $0$ (*i.e.* on ne forme aucun cluster), dans ce cas, prendre $y=0$ permet de respecter les contraintes. Cette propriété jouera un rôle intéressant, particulièrement lors du passage au dual sur la problème de recours (cf sections suivante)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Méthode en L : Coupes de Benders\n",
    "Dans le problème présentée précédemment nous avons finalement le problème de recours $v_{\\omega}(x)$ (pour une réalisation $\\omega$ des incertitudes) qui peut se présenter sous la forme suivante :\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\tv_{\\omega}(x):= \\left\\{\\begin{aligned}\n",
    "        \\underset{y}{\\max} \\quad & \\sum_{c \\in C_{K}}y_c w_c\\\\\n",
    "         s.c \\quad & y_c \\leq x_{i,j} \\xi_{i,j}(\\omega) \\quad \\forall (i,j) \\in c ~,~\\forall c \\in C_K \\\\\n",
    "         & \\sum_{c \\in C_i} y_c \\leq 1 \\quad \\forall i \\in V \\\\\n",
    "         & y_c \\leq 1 \\quad \\forall c \\in C_K\n",
    "\t\\end{aligned}\\right.\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "Nous pouvons proposer un dual pour ce problème :\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\td_{\\omega}(x):= \\left\\{\\begin{aligned}\n",
    "        \\underset{y}{\\min} \\quad & \\sum_{c \\in C_{K}}\\sum_{(i,j) \\in c} \\lambda_{(i,j)}^c x_{i,j}\\xi_{i,j}(\\omega) + \\sum_{i \\in V}\\mu_i + \\sum_{c \\in C_K} \\Delta_c\\\\\n",
    "         s.c \\quad & \\sum_{i \\in c} \\mu_i + \\Delta_c + \\sum_{(i,j) \\in c} \\lambda_{(i,j)}^c\\geq w_c \\quad \\forall c \\in C_K \\\\\n",
    "\t\\end{aligned}\\right.\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "Nous pouvons faire une remarque intéressante ici. Le polyhèdre $P$ définit par :\n",
    "\n",
    "$$\n",
    "P := \\{\\lambda, \\mu, \\Delta \\quad |\\quad \\sum_{i \\in c} \\mu_i + \\Delta_c + \\sum_{(i,j) \\in c} \\lambda_{(i,j)}^c\\geq w_c \\quad \\forall c \\in C_K\\}\n",
    "$$\n",
    "\n",
    "Ne dépend pas de la réalisation $\\omega$ des incertitudes. Nous noterons, par la suite, $\\Lambda(P)$ les points extrèmes de ce polyhèdre. A noter que ici notre problème\n",
    "\n",
    "Par dualité forte nous avons :\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\tv_{\\omega}(x)= d_{\\omega}(x)= \\left\\{\\begin{aligned}\n",
    "        \\underset{y}{\\min} \\quad & \\sum_{c \\in C_{K}}\\sum_{(i,j) \\in c} \\lambda_{(i,j)}^c x_{i,j}\\xi_{i,j}(\\omega) + \\sum_{i \\in V}\\mu_i + \\sum_{c \\in C_K} \\Delta_c\\\\\n",
    "         s.c \\quad & \\lambda, \\mu, \\Delta ~\\in~\\Lambda(P)\\\\\n",
    "\t\\end{aligned}\\right.\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "Ainsi nous avons :\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\tv_{\\omega}(x):= \\left\\{\\begin{aligned}\n",
    "        \\underset{y}{\\max} \\quad & \\theta \\\\\n",
    "         s.c \\quad & \\theta \\leq \\sum_{c \\in C_{K}}\\sum_{(i,j) \\in c} \\lambda_{(i,j)}^c x_{i,j}\\xi_{i,j}(\\omega) + \\sum_{i \\in V}\\mu_i + \\sum_{c \\in C_K} \\Delta_c \\quad\\forall~\\lambda, \\mu, \\Delta ~\\in~\\Lambda(P)\\\\\n",
    "\t\\end{aligned}\\right.\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "Nous pouvons finalement réecrir notre problème principal, de la manière suivante :\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\t\\mathbb{CP}:= \\left\\{\\begin{aligned}\n",
    "        \\underset{x}{\\max} \\quad & \\mathbb{E}_{\\omega}[\\theta(\\omega)] \\\\\n",
    "         s.c &\\quad \\theta(\\omega) \\leq \\sum_{c \\in C_{K}}\\sum_{(i,j) \\in c} \\lambda_{(i,j)}^c x_{i,j}\\xi_{i,j}(\\omega) + \\sum_{i \\in V}\\mu_i + \\sum_{c \\in C_K} \\Delta_c \\quad\\forall~\\lambda, \\mu, \\Delta ~\\in~\\Lambda(P)\\quad \\forall \\omega \\in \\Omega\\\\\n",
    "         &\\quad x_{i,j} = x_{j,i}\\quad \\forall (i,j) \\in V\\times V\\\\\n",
    "         &\\quad x_{i,j} + x_{j,k} -1 \\leq x_{i,k} \\quad \\forall (i,j,k) \\in V\\times V\\times V\\\\\n",
    "         &\\quad \\sum_{j \\in V} x_{i,j} \\leq U \\quad \\forall i \\in V \\\\\n",
    "\t\\end{aligned}\\right.\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "<ins>La méthode de Benders</ins> :\n",
    "\n",
    "La méthode en L (ou méthode de Benders) consistera à ne pas considérer l'ensemble $\\Lambda(P)$ car combinatoire, mais considérer l'ensemble $\\tilde{\\Lambda}(P) \\subset \\Lambda(P)$. Nous résolvons la régularisation suivante :\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\t\\tilde{\\mathbb{CP}}:= \\left\\{\\begin{aligned}\n",
    "        \\underset{x}{\\max} \\quad & \\mathbb{E}_{\\omega}[\\theta(\\omega)] \\\\\n",
    "         s.c &\\quad \\theta(\\omega) \\leq \\sum_{c \\in C_{K}}\\sum_{(i,j) \\in c} \\lambda_{(i,j)}^c x_{i,j}\\xi_{i,j}(\\omega) + \\sum_{i \\in V}\\mu_i + \\sum_{c \\in C_K} \\Delta_c \\quad\\forall~\\lambda, \\mu, \\Delta ~\\in~\\tilde{\\Lambda}(P)\\quad \\forall \\omega \\in \\Omega\\\\\n",
    "         &\\quad x_{i,j} = x_{j,i}\\quad \\forall (i,j) \\in V\\times V\\\\\n",
    "         &\\quad x_{i,j} + x_{j,k} -1 \\leq x_{i,k} \\quad \\forall (i,j,k) \\in V\\times V\\times V\\\\\n",
    "         &\\quad \\sum_{j \\in V} x_{i,j} \\leq U \\quad \\forall i \\in V \\\\\n",
    "\t\\end{aligned}\\right.\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "La résolution de ce problème nous donne une valeur de $x$ (solution de premier niveau) ainsi que de $\\theta$. Ainsi pour cette valeur de $x$ donnée ainsi que pour l'ensemble de nos scénarios $\\omega$ nous résolvons les différents problèmes $d_{\\omega}(x)$. La résolution de ces différents problèmes pour chaque scénarios nous donne de nouveaux points extrèmes $(\\lambda(\\omega), \\mu(\\omega), \\Delta(w))$ du polyhèdre $\\Lambda(P)$. \n",
    "\n",
    "La question étant : est-il judicieux d'ajouter ces points extrèmes à notre sous ensemble ? En effet, ajouter des points extrèmes fait grossir notre problème et le rend par conséquent plus lent pour la résolution. Nous donnons ici un test nous permettant de répondre à cette question\n",
    "\n",
    "Pour chaque scénario $\\omega$ nous disposons de la variable $\\theta(\\omega)$ (suite à la première résolution), ainsi nous vérifions :\n",
    "\n",
    "$$\n",
    "\\theta(\\omega) \\leq \\sum_{c \\in C_{K}}\\sum_{(i,j) \\in c} \\lambda_{(i,j)}^c(\\omega) x_{i,j}\\xi_{i,j}(\\omega) + \\sum_{i \\in V}\\mu_i(\\omega) + \\sum_{c \\in C_K} \\Delta_c(\\omega) + \\epsilon\n",
    "$$\n",
    "\n",
    "Où $\\epsilon > 0$ est une tolérance choisi arbitrairement petite. Si cette condition est vérifié, le point extrème trouvé n'est pas utile, sinon nous le rajoutons à notre ensemble (cela fait une contrainte ajoutée à notre problème initial), puis nous reprenons depuis le début.\n",
    "\n",
    "Si a une itération, pour tous les scénarios $\\omega$ tous les points extrèmes ajoutés ne sont pas judicieux à ajouter alors nous arrétons."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous proposons ici la méthode `LshapeClusterMethod` qui nous permet de fournir la méthode Benders pour notre problème avec les *clusters*. Le prototype de la fonction est donné dans la cellule suivante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```\n",
      "LshapeClusterMethod\n",
      "```\n",
      "\n",
      "This method propose the Benders method for the clustering problem. This method uses functions available in the files :\n",
      "\n",
      "  * recourse_problem.jl\n",
      "  * master_problem.jl\n",
      "\n",
      "# Parameters\n",
      "\n",
      "  * `kep_graph` : the graph of the kidney exchange program\n",
      "  * `ClusterSize` : the size of the clusters\n",
      "  * `C` : the list of the cycle index\n",
      "  * `cycles` : the list of the real cycles\n",
      "  * `U` : the list of the utilities\n",
      "  * `vertic_cycles` : a Julia dictionnary. for each key the value is a list corresponding to the cycles involving the key\n",
      "  * `ksi` : the tensor of the scenarios\n",
      "  * `itmax` : the number of maximum iteration\n",
      "  * `verbose` : if true, the main steps will be printed on the standard output.\n",
      "\n",
      "# Returns\n",
      "\n",
      "This method returns a dictionnary with the following keys :\n",
      "\n",
      "  * `first_level_var` : the value of x i.e. the first level solution.\n",
      "  * `objective_value` : the objective value.\n",
      "  * `nb_added_constraints` : the number of constraints we added through the iterations of the algorithm\n",
      "  * `optimal` : a boolean value : true : the problem is solved\n",
      "  * `nb_iterations` : the number of iterations the algorithm did\n"
     ]
    }
   ],
   "source": [
    "print(@doc(LshapeClusterMethod))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Premiers tests sur la méthode en L"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons venir tester cette méthode sur plusieurs exemples simples (pour la rapidité des calculs). Pour tester nos méthodes nous allons comparer la solution obtenu par l'algorithme de Benders et la solution du problème déroulé *i.e.* la solution du problème où on écrit toutes les contraintes pour chaque scénarios. On écrit comme un programme linéaire le problème $\\mathbb{CP}$. Cette dernière méthode donne la solution théorique que l'on doit trouver. L'algorithme de Benders doit-il trouver cette solution là. Non pas forcément, la méthode de Benders utilise une relaxation linéaire (on considère les variables de recours comme continues et non plus binaires) lors de la résolution des problèmes de recours, de manière à en fournir un dual, qui sera ensuite ajouté à notre problème principal. Nous savons cependant que comme la méthode de Benders résoud une relaxation linéaire la solution qu'elle fournit doit-être au moins supérieur ou égale à la solution du problème déroulé.\n",
    "\n",
    "Pour les différentes résolutions, nous utiliserons les paramètres suivant :\n",
    "- $3$ comme taille maximum de cycles\n",
    "- $10$ comme taille de cluster\n",
    "- $100$ scénarios\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infeasible Problem\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>9×6 DataFrame</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">Benders_status</th><th style = \"text-align: left;\">nb_benders_iterations</th><th style = \"text-align: left;\">nb_added_constraints</th><th style = \"text-align: left;\">objective_benders</th><th style = \"text-align: left;\">unroll_objective</th><th style = \"text-align: left;\">number_of_cycles</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"Bool\" style = \"text-align: left;\">Bool</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: right;\">true</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">14</td><td style = \"text-align: right;\">0.28</td><td style = \"text-align: right;\">0.28</td><td style = \"text-align: right;\">2</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: right;\">true</td><td style = \"text-align: right;\">4</td><td style = \"text-align: right;\">85</td><td style = \"text-align: right;\">1.16</td><td style = \"text-align: right;\">1.16</td><td style = \"text-align: right;\">10</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: right;\">true</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">20</td><td style = \"text-align: right;\">0.4</td><td style = \"text-align: right;\">0.4</td><td style = \"text-align: right;\">2</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4</td><td style = \"text-align: right;\">false</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">-1.0</td><td style = \"text-align: right;\">-1.0</td><td style = \"text-align: right;\">0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5</td><td style = \"text-align: right;\">true</td><td style = \"text-align: right;\">10</td><td style = \"text-align: right;\">259</td><td style = \"text-align: right;\">1.14</td><td style = \"text-align: right;\">1.14</td><td style = \"text-align: right;\">17</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">6</td><td style = \"text-align: right;\">true</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">28</td><td style = \"text-align: right;\">0.56</td><td style = \"text-align: right;\">0.56</td><td style = \"text-align: right;\">4</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">7</td><td style = \"text-align: right;\">true</td><td style = \"text-align: right;\">3</td><td style = \"text-align: right;\">34</td><td style = \"text-align: right;\">0.71</td><td style = \"text-align: right;\">0.71</td><td style = \"text-align: right;\">6</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">8</td><td style = \"text-align: right;\">true</td><td style = \"text-align: right;\">8</td><td style = \"text-align: right;\">261</td><td style = \"text-align: right;\">1.37</td><td style = \"text-align: right;\">1.37</td><td style = \"text-align: right;\">20</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">9</td><td style = \"text-align: right;\">true</td><td style = \"text-align: right;\">7</td><td style = \"text-align: right;\">133</td><td style = \"text-align: right;\">1.71</td><td style = \"text-align: right;\">1.71</td><td style = \"text-align: right;\">19</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccc}\n",
       "\t& Benders\\_status & nb\\_benders\\_iterations & nb\\_added\\_constraints & objective\\_benders & \\\\\n",
       "\t\\hline\n",
       "\t& Bool & Int64 & Int64 & Float64 & \\\\\n",
       "\t\\hline\n",
       "\t1 & 1 & 2 & 14 & 0.28 & $\\dots$ \\\\\n",
       "\t2 & 1 & 4 & 85 & 1.16 & $\\dots$ \\\\\n",
       "\t3 & 1 & 2 & 20 & 0.4 & $\\dots$ \\\\\n",
       "\t4 & 0 & 0 & 0 & -1.0 & $\\dots$ \\\\\n",
       "\t5 & 1 & 10 & 259 & 1.14 & $\\dots$ \\\\\n",
       "\t6 & 1 & 2 & 28 & 0.56 & $\\dots$ \\\\\n",
       "\t7 & 1 & 3 & 34 & 0.71 & $\\dots$ \\\\\n",
       "\t8 & 1 & 8 & 261 & 1.37 & $\\dots$ \\\\\n",
       "\t9 & 1 & 7 & 133 & 1.71 & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m9×6 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m Benders_status \u001b[0m\u001b[1m nb_benders_iterations \u001b[0m\u001b[1m nb_added_constraints \u001b[0m\u001b[1m objective_\u001b[0m ⋯\n",
       "     │\u001b[90m Bool           \u001b[0m\u001b[90m Int64                 \u001b[0m\u001b[90m Int64                \u001b[0m\u001b[90m Float64   \u001b[0m ⋯\n",
       "─────┼──────────────────────────────────────────────────────────────────────────\n",
       "   1 │           true                      2                    14             ⋯\n",
       "   2 │           true                      4                    85\n",
       "   3 │           true                      2                    20\n",
       "   4 │          false                      0                     0\n",
       "   5 │           true                     10                   259             ⋯\n",
       "   6 │           true                      2                    28\n",
       "   7 │           true                      3                    34\n",
       "   8 │           true                      8                   261\n",
       "   9 │           true                      7                   133             ⋯\n",
       "\u001b[36m                                                               3 columns omitted\u001b[0m"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = DataFrame(\n",
    "    Benders_status = Bool[], \n",
    "    nb_benders_iterations = Int[] , \n",
    "    nb_added_constraints = Int[], \n",
    "    objective_benders = Float64[], \n",
    "    unroll_objective = Float64[],\n",
    "    number_of_cycles = Int[]\n",
    ")\n",
    "\n",
    "for k in 1:1:9\n",
    "    try\n",
    "        kep_graph = read_kep_file(\"./_cache/data/MD-00001-0000000$k.wmd\",\"./_cache/data/MD-00001-0000000$k.dat\");\n",
    "        failure_rates = get_failure_rates(kep_graph, \"Constant\");\n",
    "\n",
    "        data = extractCycleInformation(kep_graph, 3, \"sum\");\n",
    "        C = data[\"Cycles_index\"] \n",
    "        cycles = data[\"Cycles\"]\n",
    "        U = data[\"U\"]\n",
    "        ClusterSize = 10\n",
    "        vertic_cycles = data[\"vertic_cycles\"]\n",
    "        nb_scenar = 100\n",
    "\n",
    "        ksi = getScenarioClusterK(kep_graph, nb_scenar)\n",
    "\n",
    "        res_lshape = LshapeClusterMethod(kep_graph, ClusterSize, C, cycles, U, vertic_cycles, ksi, 50, 1e-3, false)\n",
    "        res_unroll = unrollClusterProblem(kep_graph, ClusterSize, C, cycles, U, ksi, vertic_cycles)\n",
    "        optimize!(res_unroll[\"model\"])\n",
    "\n",
    "        push!(df, [res_lshape[\"optimal\"] \n",
    "        res_lshape[\"nb_iterations\"] \n",
    "        res_lshape[\"nb_added_constraints\"] \n",
    "        res_lshape[\"objective_value\"] \n",
    "        objective_value(res_unroll[\"model\"]) \n",
    "        length(cycles)])\n",
    "\n",
    "    catch\n",
    "        push!(df, [false 0 0 -1.0 -1.0 0])\n",
    "    end\n",
    "end\n",
    "\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons remarquer ici que l'instance `./_cache/data/MD-00001-00000004` pose un problème, cela est du au fait que cette instance ne possède aucun cycle et n'est donc en aucun cas intéressante pour la suite. \n",
    "\n",
    "Dans les autres cas, nous avons exactement les mêmes valeurs entre les deux méthodes et de plus la méthode de Benders à été utilisée, on peut en effet voir que le nombre de contraintes ajoutées et le nombre d'itérations de l'algorithme de Benders sont non nulles.\n",
    "\n",
    "On peut remarquer que les intstance `./_cache/data/MD-00001-00000005` et `./_cache/data/MD-00001-00000008` donnent beaucoup plus de mal, et générent un nombre de contraintes et d'itérations beaucoup plus important que dans le cas des autres instances. Nous pouvons regarder ces instances en particulier et noter que sans surprise nous avons un nombre de cycles dans le graphe qui est beaucoup plus important, en effet beaucoup de cycle dans un graphe va venir faire augmenter considérablement la taille de notre problème dans la méthode de Benders. \n",
    "\n",
    "Nous pouvons voir ici une problématique de notre implémentation quand le graphe sera très dense (beaucoup d'arrètes et donc beaucoup de cycles), notre problème maître va grossir et donc va être de plus en plus compliquer à résoudre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelisation averse au risque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.2",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
